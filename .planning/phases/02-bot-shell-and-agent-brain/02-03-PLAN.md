---
phase: 02-bot-shell-and-agent-brain
plan: 03
type: execute
wave: 2
depends_on: [02-01, 02-02]
files_modified:
  - src/channels/telegram/adapter.ts
  - src/brain/context-builder.ts
  - src/brain/system-prompt.ts
  - src/brain/router.ts
  - src/bot/index.ts
autonomous: true
requirements: [MSG-01, MSG-03, MSG-04]

must_haves:
  truths:
    - "User sends a message in Telegram and receives a contextually appropriate response from Claude"
    - "Bot auto-detects Russian or English and responds in the same language"
    - "Conversation context from all three memory tiers is assembled and fed to Claude"
    - "Multi-step conversation works: bot remembers what was said earlier in the session"
  artifacts:
    - path: "src/channels/telegram/adapter.ts"
      provides: "Telegram ChannelAdapter implementation"
      exports: ["TelegramAdapter"]
    - path: "src/brain/context-builder.ts"
      provides: "Three-tier context assembly pipeline"
      exports: ["buildContext"]
    - path: "src/brain/system-prompt.ts"
      provides: "Claude system prompt with persona and instructions"
      exports: ["buildSystemPrompt"]
    - path: "src/brain/router.ts"
      provides: "Message router connecting adapters to Claude"
      exports: ["MessageRouter"]
    - path: "src/bot/index.ts"
      provides: "Refactored bot entry point using adapter pattern"
  key_links:
    - from: "src/brain/router.ts"
      to: "src/brain/context-builder.ts"
      via: "buildContext called for every incoming message"
      pattern: "buildContext"
    - from: "src/brain/router.ts"
      to: "src/llm/client.ts"
      via: "callClaude with assembled context"
      pattern: "callClaude"
    - from: "src/brain/router.ts"
      to: "src/channels/telegram/adapter.ts"
      via: "adapter.send() for outgoing responses"
      pattern: "adapter\\.send"
    - from: "src/brain/context-builder.ts"
      to: "src/memory/short-term.ts"
      via: "getRecent for today's messages"
      pattern: "shortTerm"
    - from: "src/brain/context-builder.ts"
      to: "src/memory/long-term.ts"
      via: "search for semantic recall"
      pattern: "longTerm"
    - from: "src/bot/index.ts"
      to: "src/brain/router.ts"
      via: "MessageRouter processes all incoming messages"
      pattern: "MessageRouter"
---

<objective>
Refactor the Telegram bot into the ChannelAdapter pattern and build the conversation brain (context builder, system prompt, message router). This connects the existing Telegram bot to Claude through the three-tier memory system, enabling contextual conversations.

Purpose: This is the core conversational loop — user sends a message, context is assembled from memory, Claude generates a response with the right persona and language, and the response is sent back. MSG-01 (Telegram interaction), MSG-03 (language detection), and MSG-04 (context retention) are delivered here.

Output: Working Telegram conversational bot with Claude brain, context assembly from three memory tiers, language-aware responses, and the existing /start and /health commands preserved.
</objective>

<execution_context>
@C:/Users/dimsh/.claude/get-shit-done/workflows/execute-plan.md
@C:/Users/dimsh/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-bot-shell-and-agent-brain/02-RESEARCH.md
@.planning/phases/02-bot-shell-and-agent-brain/02-01-SUMMARY.md
@.planning/phases/02-bot-shell-and-agent-brain/02-02-SUMMARY.md
@src/bot/index.ts
@src/llm/client.ts
@src/channels/types.ts
@src/brain/language.ts
@src/memory/short-term.ts
@src/memory/medium-term.ts
@src/memory/long-term.ts
@src/memory/embedder.ts
@src/config/env.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create Telegram adapter, context builder, and system prompt</name>
  <files>src/channels/telegram/adapter.ts, src/brain/context-builder.ts, src/brain/system-prompt.ts</files>
  <action>
Create `src/channels/telegram/adapter.ts` implementing the `ChannelAdapter` interface:
- Class `TelegramAdapter` implements `ChannelAdapter`
- Constructor accepts the grammY `Bot` instance and admin chat ID string
- `channelType` readonly property returns `'telegram'`
- `start()` — Call `bot.start()` (already handled by grammY)
- `stop()` — Call `bot.stop()`
- `send(message: OutboundMessage)` — Call `bot.api.sendMessage(message.channelId, message.text, { parse_mode: 'HTML' })`. Use HTML parse mode for structured responses with lists and headers.
- `onMessage(handler: MessageHandler)` — Register a grammY middleware that:
  1. Filters non-text messages (skip if no `ctx.message?.text`)
  2. Checks admin guard: `ctx.from?.id.toString() === adminChatId` — silently ignore non-admin
  3. Constructs `InboundMessage` from grammY context:
     - `id`: `ctx.update.update_id.toString()`
     - `channelType`: `'telegram'`
     - `channelId`: `ctx.chat!.id.toString()`
     - `userId`: `ctx.from!.id.toString()`
     - `text`: `ctx.message!.text`
     - `timestamp`: `new Date(ctx.message!.date * 1000)`
     - `replyToMessageId`: `ctx.message!.reply_to_message?.message_id?.toString()`
  4. Calls `handler(inboundMessage)`
- IMPORTANT: The onMessage handler must be registered BEFORE bot.start() is called. The adapter stores handlers and registers them as grammY middleware.

Create `src/brain/context-builder.ts`:
- Function `buildContext(message: InboundMessage, shortTerm: ShortTermMemory, mediumTerm: MediumTermMemory, longTerm: LongTermMemory): Promise<string>`
- Steps:
  1. Get last 20 messages from short-term memory (Redis) for this channelId
  2. Get last 7 days of messages from medium-term memory (PostgreSQL) for this channelId, limit 50
  3. Search long-term memory (Qdrant) for semantically similar messages, limit 5
  4. Format into structured context string:
     ```
     ## Recent conversation (today)
     [user]: message text
     [assistant]: response text
     ...

     ## Earlier context (this week)
     [date] [user]: message text
     ...

     ## Related past conversations
     [date] [user]: message text (relevance: 0.85)
     ...
     ```
  5. Apply token budget: truncate if total context exceeds ~3000 tokens (rough estimate: 4 chars = 1 token, so ~12000 chars). Prioritize short-term > medium-term > long-term.
- Handle errors gracefully: if Qdrant is down, skip long-term results and log warning. If Redis is down, skip short-term and log warning. Context assembly should never fail — degrade gracefully.

Create `src/brain/system-prompt.ts`:
- Function `buildSystemPrompt(language: Language): string`
- Returns the system prompt for Claude containing:
  - Persona: friendly colleague named Astra, not formal assistant. Has character, can joke, express opinions on work topics.
  - Language instruction: "The user is writing in {language}. Always respond in the same language."
  - When doesn't know: "If you don't know something, honestly say so. Never make things up."
  - Response format: Use structured format when appropriate (lists, headers). Use emojis moderately for readability (checkmarks, warnings).
  - Response length: Short for simple questions, detailed for complex topics.
  - Action confirmation: "If the user asks you to perform an external action (create task, send email, etc.), always describe what you'll do and ask for confirmation before proceeding."
  - Context instruction: "Below is conversation history and relevant context. Use it to provide contextual responses."
- The system prompt should be relatively compact (~400-500 tokens)

Import types from `../channels/types.js`, memory classes from `../memory/*.js`, language types from `./language.js`. Use ESM `.js` extensions.
  </action>
  <verify>
    <automated>npx tsc --noEmit</automated>
    <manual>Verify TelegramAdapter implements ChannelAdapter; buildContext and buildSystemPrompt are exported</manual>
  </verify>
  <done>Telegram adapter wraps grammY Bot into ChannelAdapter interface with admin guard. Context builder assembles three-tier memory into structured text with graceful degradation. System prompt defines Astra's persona, language awareness, and response guidelines.</done>
</task>

<task type="auto">
  <name>Task 2: Create message router and refactor bot entry point</name>
  <files>src/brain/router.ts, src/bot/index.ts</files>
  <action>
Create `src/brain/router.ts` — the central message processing engine:
- Class `MessageRouter`
- Constructor accepts: `{ shortTerm: ShortTermMemory, mediumTerm: MediumTermMemory, longTerm: LongTermMemory, adapters: ChannelAdapter[] }`
- `process(message: InboundMessage): Promise<OutboundMessage>` — The main processing pipeline:
  1. Detect language using `detectLanguage(message.text)`
  2. Build context using `buildContext(message, shortTerm, mediumTerm, longTerm)`
  3. Build system prompt using `buildSystemPrompt(language)`
  4. Combine system prompt and context
  5. Call Claude via `callClaude(message.text, { system: systemPromptWithContext })` using the existing LLM client
  6. Store user message in all three memory tiers:
     - Short-term (Redis): immediately, synchronous
     - Medium-term (PostgreSQL): immediately, synchronous
     - Long-term (Qdrant): async/fire-and-forget (embed then store, don't block response)
  7. Store assistant response in all three tiers (same pattern)
  8. Create correlation ID and write audit entry for the exchange
  9. Return OutboundMessage with Claude's response text
- `registerAdapters(): void` — For each adapter, call `adapter.onMessage(handler)` where handler calls `this.process()` and then `adapter.send(response)`
- `start(): Promise<void>` — Call `registerAdapters()`, then start all adapters
- `stop(): Promise<void>` — Stop all adapters
- Error handling in the message handler: catch errors, log them, send a user-friendly error message ("Sorry, something went wrong. I'll try again." in the detected language). Never crash on a single message failure.

Refactor `src/bot/index.ts`:
- Remove the inline message handling middleware (the current correlation ID middleware stays conceptually but moves into the adapter)
- Keep `/start` and `/health` command handlers as grammY commands on the Bot instance
- Create the grammY Bot instance
- Create TelegramAdapter wrapping the Bot
- Create Redis instance (import from ioredis)
- Create ShortTermMemory with Redis
- Create MediumTermMemory with db
- Create QdrantClient and LongTermMemory
- Create MessageRouter with all memory tiers and [telegramAdapter]
- On startup:
  1. Initialize embedder (`initEmbedder()`) — trigger model download, log progress
  2. Ensure Qdrant collection exists (`longTermMemory.ensureCollection()`)
  3. Start health checker
  4. Start message router (which starts all adapters including Telegram)
- Preserve graceful shutdown: stop router, stop health checker, close DB
- IMPORTANT: Keep /start, /health, /settings commands registered on the Bot BEFORE passing it to the adapter. The adapter registers its onMessage handler after commands, so grammY's command handlers take priority.

Use existing imports: `callClaude` from `../llm/client.js`, `createRequestLogger` from `../logging/correlation.js`, `writeAuditEntry` from `../logging/audit.js`, `logger` from `../logging/logger.js`. Use `{ Redis }` named import from `ioredis`.
  </action>
  <verify>
    <automated>npx tsc --noEmit</automated>
    <manual>Verify MessageRouter is exported with process/start/stop methods; bot/index.ts creates router with Telegram adapter and memory tiers</manual>
  </verify>
  <done>Message router processes incoming messages through language detection, three-tier context assembly, and Claude conversation. Bot entry point refactored to use adapter pattern with memory initialization. Existing /start and /health commands preserved. Graceful error handling on individual messages.</done>
</task>

</tasks>

<verification>
- `npx tsc --noEmit` passes with zero errors
- Bot entry point initializes embedder, Qdrant collection, memory tiers, and router
- Telegram adapter implements ChannelAdapter interface with admin-only guard
- Context builder assembles from all three memory tiers with graceful degradation
- Message router calls Claude with context and language-aware system prompt
- Messages stored in all three memory tiers after processing
- Existing /start and /health commands still work
</verification>

<success_criteria>
- User sends a Telegram message and receives a Claude-generated response
- Response language matches the message language (Russian/English)
- Conversation context is assembled from Redis + PostgreSQL + Qdrant
- Multi-step conversation works: bot retains context within a session
- Errors on individual messages don't crash the bot
- Graceful shutdown stops all components cleanly
</success_criteria>

<output>
After completion, create `.planning/phases/02-bot-shell-and-agent-brain/02-03-SUMMARY.md`
</output>
